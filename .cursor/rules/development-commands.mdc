---
description: 
globs: 
alwaysApply: true
---
# Development Commands & Workflows

## ðŸš€ Essential Commands

### Complete Data Pipeline
```bash
# Process all transaction files and generate normalized data (MAIN COMMAND)
PYTHONPATH=$(pwd) python -c "from app.ingestion.loader import process_transactions; result_df = process_transactions('data/transaction_history', 'config/schema_mapping.yaml'); result_df.to_csv('output/transactions_normalized.csv', index=False); print(f'Processed {len(result_df)} transactions')"
```

### Application Launch
```bash
# Enhanced dashboard (PRODUCTION) - Port 8502
PYTHONPATH=$(pwd) streamlit run ui/streamlit_app_v2.py --server.port 8502

# API server with auto-reload - Port 8000
uvicorn app.api:app --reload --port 8000

# Production API server
uvicorn app.api:app --host 0.0.0.0 --port 8000 --workers 4

# Legacy dashboard - Port 8501
PYTHONPATH=$(pwd) streamlit run ui/streamlit_app.py --server.port 8501
```

### uv-based Development
```bash
# Environment setup
uv venv && source .venv/bin/activate
uv pip install -e ".[dev]"

# Daily development
uv pip install package_name
uv pip compile pyproject.toml --output-file requirements.lock
uv pip compile pyproject.toml --extra dev --output-file requirements-dev.lock

# Development tools
black .
ruff check .
mypy .
pytest
```

## ðŸ§ª Testing & Validation

### Test Suite
```bash
# Full test suite (93.4% pass rate)
python -m pytest tests/ -v

# Test with coverage
python -m pytest tests/ --cov=app --cov=ui --cov-report=html

# Specific test modules
python -m pytest tests/test_cost_basis.py -v
python -m pytest tests/test_normalization.py -v
python -m pytest tests/test_portfolio.py -v
python -m pytest tests/test_normalization_comprehensive.py -v
```

### Portfolio Testing
```bash
# Main portfolio calculation test
python scripts/testing/test_portfolio_cleaned.py

# Debug portfolio issues
python scripts/debug/debug_portfolio_issues.py

# Performance benchmark
python scripts/simple_benchmark.py
```

### Data Quality Validation
```bash
# Quick health check
python -c "import app, ui, scripts; print('âœ… All modules import successfully')"

# Data quality overview
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv', parse_dates=['timestamp']); print(f'Loaded {len(df)} transactions'); print(f'Unknown types: {(df[\"type\"] == \"unknown\").sum()}'); print(f'Duplicates: {df.duplicated().sum()}')"

# Detailed data quality check
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv', parse_dates=['timestamp']); print('Data Quality Checks:'); print(f'Missing timestamps: {df[\"timestamp\"].isna().sum()}'); print(f'Missing assets: {df[\"asset\"].isna().sum()}'); print(f'Missing quantities: {df[\"quantity\"].isna().sum()}'); print(f'Zero quantities: {(df[\"quantity\"] == 0).sum()}'); print(f'Unknown types: {(df[\"type\"] == \"unknown\").sum()}'); duplicates = df.duplicated(subset=['timestamp', 'asset', 'quantity', 'price', 'institution']).sum(); print(f'Duplicate transactions: {duplicates}')"
```

### Transaction Analysis
```bash
# Transaction count by institution
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv'); print(df['institution'].value_counts())"

# Transaction types analysis
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv'); print(df['type'].value_counts())"

# Unknown transaction types
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv'); unknown = df[df['type'] == 'unknown']; print(f'Unknown types: {len(unknown)}'); print(unknown[['timestamp', 'type', 'asset', 'institution']].head())"

# Asset coverage
python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv'); print(f'Total assets: {df[\"asset\"].nunique()}'); print('Assets:', sorted(df['asset'].unique()))"
```

## ðŸ’° Historical Price Data Commands

### Price Data Validation
```bash
# Check historical price data coverage
python -c "import os; import glob; files = glob.glob('data/historical_price_data/*.csv'); print(f'Historical price files: {len(files)}'); [print(f.split('/')[-1]) for f in files[:10]]"

# Test portfolio calculation with historical prices
python -c "import pandas as pd; from app.analytics.portfolio import compute_portfolio_time_series_with_external_prices; df = pd.read_csv('output/transactions_normalized.csv', parse_dates=['timestamp']); result = compute_portfolio_time_series_with_external_prices(df); print(f'Portfolio calculation result: {result.shape}'); print(f'Latest portfolio value: ${result[\"total\"].iloc[-1]:,.2f}' if not result.empty else 'No data')"

# Check price data loading for specific asset
python -c "from app.analytics.portfolio import load_historical_price_csv; from datetime import datetime; result = load_historical_price_csv('BTC', datetime(2020, 1, 1), datetime(2024, 12, 31)); print(f'BTC price data: {result.shape if result is not None else \"Not found\"}')"
```

## ðŸ”§ Database & Migration

### Database Operations
```bash
# Run database migration
python migration.py

# Reset database (careful!)
rm portfolio.db && python migration.py

# Check database tables
python -c "import sqlite3; conn = sqlite3.connect('portfolio.db'); cursor = conn.cursor(); cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\"); print([row[0] for row in cursor.fetchall()]); conn.close()"

# Update positions from transactions
python -c "from app.ingestion.update_positions import update_positions_from_transactions; update_positions_from_transactions()"
```

## ðŸš€ Performance & Monitoring

### Performance Benchmarking
```bash
# Data loading benchmark
python scripts/simple_benchmark.py

# Memory usage monitoring
python -c "import psutil; print(f'Memory usage: {psutil.Process().memory_info().rss / 1024 / 1024:.1f} MB')"

# Time data loading
time python -c "import pandas as pd; df = pd.read_csv('output/transactions_normalized.csv'); print(f'Loaded {len(df)} transactions')"

# Time portfolio calculation
time python scripts/testing/test_portfolio_cleaned.py
```

### System Resource Monitoring
```bash
# Check memory usage
python -c "import psutil; print(f'Memory: {psutil.virtual_memory().percent}%')"

# Check disk usage
df -h

# Monitor Python process
top -p $(pgrep -f streamlit)
```

## ðŸ“Š API Testing

### API Endpoints
```bash
# Health check
curl http://localhost:8000/health

# Portfolio value
curl "http://localhost:8000/portfolio/value?target_date=2024-01-15"

# Portfolio returns
curl "http://localhost:8000/portfolio/returns?start_date=2024-01-01&end_date=2024-01-31"
```

## ðŸ”„ Development Workflows

### 1. Adding New Institution Support
1. Add CSV file to [data/transaction_history/](mdc:data/transaction_history)
2. Update [config/schema_mapping.yaml](mdc:config/schema_mapping.yaml)
3. Add institution detection logic in [app/ingestion/loader.py](mdc:app/ingestion/loader.py)
4. Add transaction type mappings in [app/ingestion/normalization.py](mdc:app/ingestion/normalization.py)
5. Test with `python scripts/test_normalization.py`

### 2. Adding New Asset Support
1. Add historical price CSV to [data/historical_price_data/](mdc:data/historical_price_data)
2. Update `CRYPTO_ASSET_IDS` mapping in [app/analytics/portfolio.py](mdc:app/analytics/portfolio.py)
3. Test price loading with debug script
4. Validate portfolio calculation

### 3. Dashboard Development
1. Use [ui/streamlit_app_v2.py](mdc:ui/streamlit_app_v2.py) as base
2. Add components to [ui/components/](mdc:ui/components)
3. Implement caching with `@st.cache_data(ttl=300)`
4. Test performance with real data

## ðŸ”§ Troubleshooting

### Common Issues & Quick Fixes

#### Import Errors
```bash
# Ensure project is installed in editable mode
uv pip install -e .

# Check Python path
echo $PYTHONPATH
```

#### Database Issues
```bash
# Initialize database
python scripts/migration.py

# Check database connection
python -c "from app.db.base import engine; print('âœ… Database connected')"
```

#### API Server Issues
The API server now includes proper shutdown handlers:
- Single Ctrl+C shutdown (no more double Ctrl+C needed)
- Proper database connection cleanup
- Enhanced connection pooling settings

#### Test Import Issues
All test files have been updated with correct import paths:
- [tests/test_cost_basis.py](mdc:tests/test_cost_basis.py) - Fixed imports from `app.analytics.portfolio`
- [tests/test_ingestion.py](mdc:tests/test_ingestion.py) - Fixed imports from `app.ingestion.loader`
- [tests/test_normalization.py](mdc:tests/test_normalization.py) - Fixed imports from `app.ingestion.normalization`

### Cache Management
```bash
# Clear Streamlit cache
streamlit cache clear

# Clear Python cache
find . -type d -name "__pycache__" -exec rm -rf {} +
find . -name "*.pyc" -delete
```

### Process Management
```bash
# Kill Streamlit processes
pkill -f streamlit

# Kill API server processes
pkill -f uvicorn

# Check running processes
ps aux | grep python
```

## ðŸŽ¯ Expected Healthy Results

### System Health Check
- **Transactions**: ~4,235 loaded
- **Portfolio Value**: ~$977K
- **Unknown Types**: <2%
- **Duplicates**: 0
- **Top Assets**: BTC (~$431K), VOO (~$186K), ETH (~$177K)
- **Test Pass Rate**: >93%

### Performance Targets
- **Environment Setup**: <30 seconds with uv
- **Data Processing**: <200ms for 4,000+ transactions
- **Portfolio Calculation**: <2 seconds for full analysis
- **API Response**: <200ms for portfolio queries
- **Dashboard Load**: <500ms initial load
